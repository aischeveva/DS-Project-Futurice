{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Topic:\n",
    "Is it possible to extract market trends automatically from the published data? For a consulting company like Futurice, it is important to understand emerging business trends and the market situation of client companies. \n",
    "\n",
    "The data we have available is from the [Edgar Database](https://www.sec.gov/edgar/searchedgar/companysearch.html) in form of annual reports (10-K format). The data source contains the annual financial report of all registered companies in the USA. \n",
    "\n",
    "# Our task: \n",
    "- Explore publicly available textual financial datasets using Machine Learning methods. \n",
    "- Create visualizations to highlight the most important trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathvalidate import sanitize_filename\n",
    "from bs4 import BeautifulSoup\n",
    "from download_edgar import * \n",
    "from utils import *\n",
    "from topic_classifier import *\n",
    "from topic_modeling import *\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for year 2010\n",
      "Downloading data for year 2011\n",
      "Downloading data for year 2012\n",
      "Downloading data for year 2013\n",
      "Downloading data for year 2014\n",
      "Downloading data for year 2015\n",
      "Downloading data for year 2016\n",
      "Downloading data for year 2017\n",
      "Downloading data for year 2018\n"
     ]
    }
   ],
   "source": [
    "# Download index files from start-year to end-year\n",
    "download_index(2010, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripping unnecessary tags from the text file for year 2013\n",
      "Stripping unnecessary tags from the text file for year 2014\n",
      "Stripping unnecessary tags from the text file for year 2015\n",
      "Stripping unnecessary tags from the text file for year 2012\n",
      "Stripping unnecessary tags from the text file for year 2017\n",
      "Stripping unnecessary tags from the text file for year 2010\n",
      "Stripping unnecessary tags from the text file for year 2018\n",
      "Stripping unnecessary tags from the text file for year 2011\n",
      "Stripping unnecessary tags from the text file for year 2016\n"
     ]
    }
   ],
   "source": [
    "# Clean the tags from the file\n",
    "clean_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 10-K reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 10K-report for year 2010\n",
      "Downloading 10K-report for year 2011\n",
      "Downloading 10K-report for year 2012\n",
      "Downloading 10K-report for year 2013\n",
      "Downloading 10K-report for year 2014\n",
      "Downloading 10K-report for year 2015\n",
      "Downloading 10K-report for year 2016\n",
      "Downloading 10K-report for year 2017\n",
      "Downloading 10K-report for year 2018\n",
      "Downloading 10K-report for year 2019\n"
     ]
    }
   ],
   "source": [
    "download_10_k(2010, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert 10-K reports to CIK series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 10-K to CIK for year 2010\n",
      "Converting 10-K to CIK for year 2011\n",
      "Converting 10-K to CIK for year 2012\n",
      "Converting 10-K to CIK for year 2013\n",
      "Converting 10-K to CIK for year 2014\n",
      "Converting 10-K to CIK for year 2015\n",
      "Converting 10-K to CIK for year 2016\n",
      "Converting 10-K to CIK for year 2017\n",
      "Converting 10-K to CIK for year 2018\n"
     ]
    }
   ],
   "source": [
    "rename_to_index(2010, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original text is in the following form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -k motivnationform kdec htm movt form k december motivnationform kdec htm united states securities and exchange commission washington d c form -k x annual report under section or d of the securities \n"
     ]
    }
   ],
   "source": [
    "#Read the text from uncleanned file\n",
    "f=open(\"forms/2010/1853.txt\", \"r\")\n",
    "print(f.read(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data with the following tasks:\n",
    "+ Remove stopwords\n",
    "+ Convert the text to lower case, strip punctuation, and split by spaces\n",
    "+ Lemmatize the text to its root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing the data for year 2010\n",
      "Pre-processing the data for year 2011\n",
      "Pre-processing the data for year 2012\n",
      "Pre-processing the data for year 2013\n",
      "Pre-processing the data for year 2014\n",
      "Pre-processing the data for year 2015\n",
      "Pre-processing the data for year 2016\n",
      "Pre-processing the data for year 2017\n",
      "Pre-processing the data for year 2018\n"
     ]
    }
   ],
   "source": [
    "preprocess(2010, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being pre-processed, the data is in the following form, which is sufficient for Natural Language Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motivnationform kdec movt form decemb motivnationform kdec unit state secur exchang commiss washington form annual report section secur exchang fiscal year end decemb transit report pursuant section s\n"
     ]
    }
   ],
   "source": [
    "a=open(\"cleaned/2010/1853.txt\", \"r\")\n",
    "print(a.read(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify companies into corresponding industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry a company belongs to could be queried in the [Edgar Database](https://www.sec.gov/info/edgar/siccodes.htm) using the company's SIC code.   \n",
    "#### Code Description:\n",
    "- CIK is the company's ID in Edgar database.\n",
    "- SIC is the company's business sector code defined in Edgar.\n",
    "\n",
    "Convert the CIK code to SIC code and use it to query in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying companies into industries for year 2010\n",
      "Classifying companies into industries for year 2011\n",
      "Classifying companies into industries for year 2012\n",
      "Classifying companies into industries for year 2013\n",
      "Classifying companies into industries for year 2014\n",
      "Classifying companies into industries for year 2015\n",
      "Classifying companies into industries for year 2016\n",
      "Classifying companies into industries for year 2017\n",
      "Classifying companies into industries for year 2018\n"
     ]
    }
   ],
   "source": [
    "#Convert the CIK to SIC\n",
    "cik_2_sic = CIK_2_SIC_series\n",
    "\n",
    "#Classify the company into its industry\n",
    "classify_industry(2010,2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Corpus For Training \n",
    "There are 2 scenarios:\n",
    "1. Query all available companies in all years. In this way, we can cover more textual data and obtain a comprehensive collection of topics. However, there might be the case that some trendy topics actually represent changes in the number of registered companies, rather than represent how companies are changing their business.\n",
    "2. Query only a subset of companies that appear in every years. In this way, we can study how topics of the same set of companies change over time. Nonetheless, we might lose considerable amount of information as the companies intersection over years can be small compared to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some parameters as a example:\n",
    "office = 'Office of Manufacturing'\n",
    "sector = 'Foods & Beverages'\n",
    "start_year = 2010\n",
    "end_year = 2019\n",
    "same_companies = False\n",
    "use_perplexity = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying the document for companies in year 2010\n",
      "Querying the document for companies in year 2011\n",
      "Querying the document for companies in year 2012\n",
      "Querying the document for companies in year 2013\n",
      "Querying the document for companies in year 2014\n",
      "Querying the document for companies in year 2015\n",
      "Querying the document for companies in year 2016\n",
      "Querying the document for companies in year 2017\n",
      "Querying the document for companies in year 2018\n"
     ]
    }
   ],
   "source": [
    "# Get the corpus:\n",
    "if same_companies:\n",
    "    corpus = query_intersection(2010, 2019, office, sector, False)\n",
    "else:\n",
    "    corpus = query_docs(2010, 2019, office, sector, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Documents\n",
    "The topic model should be general enough to achieve reasonable prediction. Therefore, training documents for the topic model should contains a random subset of documents from each year.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling documents in each year for training:\n",
    "docs = sampling_corpus(corpus, percent=1/(end_year - start_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Topic Models\n",
    "Latent Dirichlet Allocation (LDA) topic model (gensim) is used for topic modeling. Because LDA model depends significantly on the number of topics in a document, we trained several models on different number of topics and chose the best one based on their coherence scores and perplexity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model of 83 topics\n",
      "Building model of 93 topics\n",
      "Building model of 103 topics\n",
      "Building model of 113 topics\n",
      "Building model of 123 topics\n",
      "Building model of 133 topics\n",
      "Building model of 143 topics\n",
      "Building model of 153 topics\n"
     ]
    }
   ],
   "source": [
    "# Covert documents to tokens, bag of word and dictionary format:\n",
    "texts, bows, dic, bigram = texts_bows_dict(docs, 5, 0.5, 5, 100, True)\n",
    "    \n",
    "# Build models for comparison:\n",
    "start = max(len(docs) - 70, 10)\n",
    "end = len(docs) + 1\n",
    "step = 10\n",
    "models, coherences, perplexities = models_codherence_perplexity(\n",
    "        texts, bows, dic, topic_start=start, topic_end=end, step=step, \\\n",
    "        chunk=20, passes=3)\n",
    "\n",
    "# Choose a good model:\n",
    "if use_perplexity:\n",
    "    per = [-p for p in perplexities]\n",
    "    per = [(p - min(per))/(max(per) - min(per)) for p in per]\n",
    "    score = [per[i]*coherences[i] for i in range(len(per))]\n",
    "    which = np.argmax(score)\n",
    "else:\n",
    "    which = np.argmax(coherences)\n",
    "chosen = models[which]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Analysis\n",
    "1. A subset of topics will be chosen as preference for topic analysis because many topics are either similar to each others or hard to interpret in human level. Chosen topics should have high coherence or low correlation. To that end, top topics from both criteria are selected and then we take the union of them.\n",
    "2. Chosen LDA model is used to predict most probable topics for each document. The set of predicted topics will be processed in such a way that any topic which is not a member of the union will be replaced by a topic in the union that is most correlated to it.\n",
    "3. Count the occurrence of each topic in each year in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get texts and bows for each year:\n",
    "bows_vs_years = get_all_bows(corpus, dic, bigram)\n",
    "\n",
    "# Prepare to get topic union:\n",
    "topic_list = chosen.show_topics(chosen.num_topics, 10)\n",
    "top_topics = chosen.top_topics(texts=texts, coherence='c_v', topn=10)\n",
    "    \n",
    "# Get the correlation matrix:\n",
    "mdiff, _ = chosen.diff(chosen, distance='jaccard', num_words=100)\n",
    "    \n",
    "# Get top topics based on coherence and correlation:\n",
    "union = topic_union(top_topics, topic_list, mdiff, 10)\n",
    "    \n",
    "# Get the count for each topic in each year:\n",
    "counts = topic_count_years(bows_vs_years, chosen, 0.05, union, mdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving\n",
    "After the topic analysis, we stored the result in csv files as sources for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DataFrame:\n",
    "data = [[p[1] for p in count] for count in counts]\n",
    "pre = [' | '.join(re.findall(r'[a-z_]+', topic_list[i][1])) \\\n",
    "        for i in union]\n",
    "df = pd.DataFrame(data, columns=pre, index=range(2010, 2019))\n",
    "# Save the model:\n",
    "df.to_csv(os.getcwd()[:-3] + os.sep + 'DS/web/source/' + office + '_' + sector + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image is the change in the number of times a topic was mentioned in the Food & Beverages sector of the Office of Manufacturing (158 companies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/NVKLbG0/pre-classifier-image.png\" width=\"1000\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.ibb.co/NVKLbG0/pre-classifier-image.png\", width=1000, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask question: How to detect potential trends that happened in the past?\n",
    "## Starting point:\n",
    "At this point, it is necessary to remove the lines that remain stable over the 9-year period. It could be assumed that those lines are unlikely to be trendy in the future, and companies would be mentioning about those topics with similar frequencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels and Convert Data to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Use pandas to read csv files\n",
    "import pandas as pd\n",
    "\n",
    "# Use three sectors as the training data\n",
    "vehicles_sector = pd.read_csv(\"Office of Manufacturing_Vehicles.csv\").drop(columns = \"Unnamed: 0\")\n",
    "electronic_sector = pd.read_csv(\"Office of Manufacturing_ELectrical & Electronic.csv\").drop(columns = \"Unnamed: 0\")\n",
    "recreational_sector = pd.read_csv(\"Office of Trade & Services_Recreational Services.csv\").drop(columns = \"Unnamed: 0\")\n",
    "train_data = pd.concat([vehicles_sector,electronic_sector,recreational_sector],axis=1).T\n",
    "\n",
    "# Convert features to array\n",
    "features = np.array(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is assuming that the topic which differed by at least 10 times in the number of times being mentioned was trendy and could reveal interesting things happened in the past. We manually labelled the test data (0: uninteresting, 1: interesting) through visualizing the high chart as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to array \n",
    "labels_vehicles = np.array([0,0,0,0,1,0,0,1,0,0,0,0,1,0,0])\n",
    "labels_electronic = np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0])\n",
    "labels_recreational = np.array([0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1])\n",
    "\n",
    "labels = np.concatenate([labels_vehicles, labels_electronic, labels_recreational])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training set and testing set\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (39, 9)\n",
      "Training Labels Shape: (39,)\n",
      "Testing Features Shape: (14, 9)\n",
      "Testing Labels Shape: (14,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries for the Random Forest Algorithm \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3,random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rfc.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rfc.predict(test_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.0 %.\n"
     ]
    }
   ],
   "source": [
    "#Test the accuracy of the model \n",
    "accuracy = rfc.score(test_features, test_labels)\n",
    "print(\"Accuracy: \", round(accuracy,2) * 100, '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the Model if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create models with different hyperparameters to try and boost performance. The only way to find the best ones are to try a few and evaluate them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_new = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify unseen sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying Office of Trade & Services_Wholesale\n",
      "Classifying Office of Manufacturing_Vehicles\n",
      "Classifying Office of Trade & Services_Miscellaneous Services\n",
      "Classifying Office of Life Sciences_Measure & Control\n",
      "Classifying Office of Manufacturing_Non-Metals\n",
      "Classifying Office of Trade & Services_Social Services\n",
      "Classifying Office of Life Sciences_Agriculture\n",
      "Classifying Office of Life Sciences_Chemicals\n",
      "Classifying Office of Technology_Computer Software\n",
      "Classifying Office of Trade & Services_Recreational Services\n",
      "Classifying Office of Trade & Services_Retail\n",
      "Classifying Office of Manufacturing_Paper & Printing\n",
      "Classifying Office of Life Sciences_Medical Services\n",
      "Classifying Office of Real Estate & Construction_Construction\n",
      "Classifying Office of Energy & Transportation_Transportation\n",
      "Classifying Office of Technology_Computer Hardware\n",
      "Classifying Office of Energy & Transportation_Petroleum & Coal\n",
      "Classifying Office of Energy & Transportation_Power & Energy\n",
      "Classifying Office of Trade & Services_Advertising Services\n",
      "Classifying Office of Trade & Services_Business Services\n",
      "Classifying Office of Trade & Services_Management Services\n",
      "Classifying Office of Manufacturing_Textiles\n",
      "Classifying Office of Technology_Telecommunication\n",
      "Classifying Office of Manufacturing_Metals\n",
      "Classifying Office of Life Sciences_Medical Apparatus\n",
      "Classifying Office of Trade & Services_Research & Engineering Services\n",
      "Classifying Office of Manufacturing_Furniture\n",
      "Classifying Office of Manufacturing_Art\n",
      "Classifying Office of Technology_Machinery & Equipment\n",
      "Classifying Office of Energy & Transportation_Mining\n",
      "Classifying Office of Finance_Insurance\n",
      "Classifying Office of Finance_Trade & Investment\n",
      "Classifying Office of Manufacturing_ELectrical & Electronic\n",
      "Classifying Office of Finance_Bankings\n",
      "Classifying Office of Manufacturing_Foods & Beverages\n"
     ]
    }
   ],
   "source": [
    "# Use the saved model to classify unseen sectors\n",
    "topic_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image is an example of running topic classifier on the Mining sector of the Office of Energy & Transportation (679 companies). \n",
    "\n",
    "**From the graph, it implies companies operating within the Mining industry mentioned mostly in total 6 topics, which are shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/bRnSQpN/Screenshot-2019-11-27-at-11-23-09-PM.png\" width=\"1000\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(url=\"https://i.ibb.co/bRnSQpN/Screenshot-2019-11-27-at-11-23-09-PM.png\", width=1000, height=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
